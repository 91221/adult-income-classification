{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbc2m4QhE8-Z",
        "outputId": "9a511e72-7910-46e5-ca9c-39c64f8c68c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Adult Income Classification\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ==========================================\n",
        "# 1Ô∏è‚É£ Load Dataset\n",
        "# ==========================================\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "\n",
        "columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
        "    \"marital-status\", \"occupation\", \"relationship\", \"race\",\n",
        "    \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\",\n",
        "    \"native-country\", \"income\"\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, names=columns, sep=\", \", engine=\"python\")\n",
        "\n",
        "# ==========================================\n",
        "# 2Ô∏è‚É£ Data Cleaning\n",
        "# ==========================================\n",
        "\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(\"Dataset shape after cleaning:\", df.shape)\n",
        "\n",
        "# ==========================================\n",
        "# 3Ô∏è‚É£ Encode Categorical Variables\n",
        "# ==========================================\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# ==========================================\n",
        "# 4Ô∏è‚É£ Split Dataset\n",
        "# ==========================================\n",
        "\n",
        "X = df.drop(\"income\", axis=1)\n",
        "y = df[\"income\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 5Ô∏è‚É£ Initialize Models (Size Optimized)\n",
        "# ==========================================\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(\n",
        "        max_depth=10,   # limit depth ‚Üí smaller file\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"K-Nearest Neighbor Classifier\": KNeighborsClassifier(\n",
        "        n_neighbors=5\n",
        "    ),\n",
        "\n",
        "    \"Naive Bayes Classifier\": GaussianNB(),\n",
        "\n",
        "    \"Random Forest (Ensemble)\": RandomForestClassifier(\n",
        "        n_estimators=50,   # reduced trees\n",
        "        max_depth=12,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"XGBoost (Ensemble)\": XGBClassifier(\n",
        "        n_estimators=50,      # reduced estimators\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 6Ô∏è‚É£ Train & Evaluate\n",
        "# ==========================================\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\nTraining Models...\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        y_prob = y_pred\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    results.append([\n",
        "        name,\n",
        "        accuracy,\n",
        "        auc,\n",
        "        precision,\n",
        "        recall,\n",
        "        f1,\n",
        "        mcc\n",
        "    ])\n",
        "\n",
        "    print(f\"{name} completed.\")\n",
        "\n",
        "# ==========================================\n",
        "# 7Ô∏è‚É£ Results Table + Ranking\n",
        "# ==========================================\n",
        "\n",
        "results_df = pd.DataFrame(\n",
        "    results,\n",
        "    columns=[\n",
        "        \"Model\",\n",
        "        \"Accuracy\",\n",
        "        \"AUC Score\",\n",
        "        \"Precision\",\n",
        "        \"Recall\",\n",
        "        \"F1 Score\",\n",
        "        \"MCC\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add Ranking (Based on F1 Score)\n",
        "results_df[\"Rank\"] = results_df[\"F1 Score\"].rank(\n",
        "    ascending=False,\n",
        "    method=\"dense\"\n",
        ").astype(int)\n",
        "\n",
        "# Sort by Rank\n",
        "results_df = results_df.sort_values(\"Rank\")\n",
        "\n",
        "print(\"\\nFinal Model Comparison (Ranked by F1 Score):\\n\")\n",
        "print(results_df)\n",
        "\n",
        "# ==========================================\n",
        "# 8Ô∏è‚É£ Save Models (Compressed)\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\nSaving models...\")\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "for name, model in models.items():\n",
        "    filename = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") + \".pkl\"\n",
        "    joblib.dump(\n",
        "        model,\n",
        "        f\"model/{filename}\",\n",
        "        compress=3   # üî• reduces file size significantly\n",
        "    )\n",
        "\n",
        "joblib.dump(label_encoders, \"model/label_encoders.pkl\", compress=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz4nsSexFM_9",
        "outputId": "72ba9535-7a62-45ff-eb78-613f3f16e416"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset shape after cleaning: (30162, 15)\n",
            "\n",
            "Training Models...\n",
            "\n",
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression completed.\n",
            "Training Decision Tree Classifier...\n",
            "Decision Tree Classifier completed.\n",
            "Training K-Nearest Neighbor Classifier...\n",
            "K-Nearest Neighbor Classifier completed.\n",
            "Training Naive Bayes Classifier...\n",
            "Naive Bayes Classifier completed.\n",
            "Training Random Forest (Ensemble)...\n",
            "Random Forest (Ensemble) completed.\n",
            "Training XGBoost (Ensemble)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [14:38:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost (Ensemble) completed.\n",
            "\n",
            "Final Model Comparison (Ranked by F1 Score):\n",
            "\n",
            "                           Model  Accuracy  AUC Score  Precision    Recall  \\\n",
            "4       Random Forest (Ensemble)  0.857119   0.914436   0.782686  0.589880   \n",
            "1       Decision Tree Classifier  0.850986   0.884813   0.749380  0.603196   \n",
            "5             XGBoost (Ensemble)  0.853970   0.912733   0.787766  0.565912   \n",
            "0            Logistic Regression  0.802752   0.810695   0.678899  0.394141   \n",
            "2  K-Nearest Neighbor Classifier  0.770927   0.663644   0.570588  0.322903   \n",
            "3         Naive Bayes Classifier  0.786508   0.828922   0.656891  0.298269   \n",
            "\n",
            "   F1 Score       MCC  Rank  \n",
            "4  0.672741  0.593194     1  \n",
            "1  0.668388  0.579351     2  \n",
            "5  0.658659  0.581519     3  \n",
            "0  0.498736  0.408691     4  \n",
            "2  0.412415  0.301210     5  \n",
            "3  0.410256  0.336790     6  \n",
            "\n",
            "Saving models...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model/label_encoders.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the model folder\n",
        "shutil.make_archive(\"model\", 'zip', \"model\")\n",
        "\n",
        "# Download the zip file\n",
        "files.download(\"model.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rW6Si1IWIWaS",
        "outputId": "2fa66831-2154-40c6-885c-502630d903f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_090195b7-966e-4e88-881a-60b14d7518b1\", \"model.zip\", 1979868)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}